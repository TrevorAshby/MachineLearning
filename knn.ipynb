{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVL7_bgmIAPR"
   },
   "source": [
    "# K-Nearest Neighbor Lab\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "6ZbYjZZZ_yLV"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCcEPx5VIORj"
   },
   "source": [
    "## 1. (40%) Correctly implement the k-nearest neighbor (KNN) algorithm and the KNN regression algorithm\n",
    "\n",
    "### Code requirements\n",
    "- Use Euclidean distance to decide closest neighbors. \n",
    "- Include optional distance weighting for both algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a2KSZ_7AN0G"
   },
   "outputs": [],
   "source": [
    "class KNNClassifier(BaseEstimator,ClassifierMixin):\n",
    "    data = []\n",
    "    labels = []\n",
    "    def __init__(self, columntype=[], weight_type='inverse_distance'): ## add parameters here\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            columntype for each column tells you if continues[real] or if nominal[categoritcal].\n",
    "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.K = 3 # default set to 3\n",
    "        self.columntype = columntype # Note This won't be needed until part 5\n",
    "        self.weight_type = weight_type\n",
    "        self.isClassification = True # default is classification\n",
    "        self.isWeighted = True # default is true\n",
    "\n",
    "    def fit(self, data, labels):\n",
    "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "            y (array-like): A 2D numpy array with the training targets\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        return self\n",
    "    \n",
    "    def predict(self, data):\n",
    "        \"\"\" Predict all classes for a dataset X\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "        Returns:\n",
    "            array, shape (n_samples,)\n",
    "                Predicted target values per element in X.\n",
    "        \"\"\"\n",
    "        # The KNN Algorithm\n",
    "        # For each example in the data\n",
    "        distances_indices = []\n",
    "        for inc in range(len(self.data)):\n",
    "            sum = 0\n",
    "            for item in range(len(data)):\n",
    "                # Calculate the distance between the query example and \n",
    "                # the current example from the data.\n",
    "                # print('self.data[inc]: ', self.data[inc])\n",
    "                # print('data: ', data)\n",
    "                # print('item: ', item)\n",
    "                sum += np.abs(self.data[inc][item] - data[item])\n",
    "            # Add the distance and the index of the example to an ordered collection\n",
    "            distances_indices.append([sum, inc])\n",
    "        \n",
    "        # Sort the ordered collection of distances and indices from \n",
    "        # smallest to largest (in ascending order) by the distances\n",
    "        # print('pre-sort: ', distances_indices)\n",
    "        distances_indices = sorted(distances_indices, key=lambda x: x[0])\n",
    "        # print('post-sort: ', distances_indices)\n",
    "\n",
    "        final_selection = []\n",
    "        # Pick the first K entries from the sorted collection\n",
    "        for i in range(self.K):\n",
    "            final_selection.append(distances_indices[i])\n",
    "        \n",
    "        final_labels = []\n",
    "        # Get the labels of the selected K entries\n",
    "        # --------------------------- NEED TO FIX THIS SECTION -------------------------\n",
    "        res = None\n",
    "        avg = 0\n",
    "        if self.isWeighted:\n",
    "            for selection in final_selection:\n",
    "                if not self.isClassification:\n",
    "                    if selection[0] != 0:\n",
    "                        print('selection: ', selection[0])\n",
    "                        avg += (self.labels[selection[1]]) / ((selection[0])**2)\n",
    "                    else:\n",
    "                        avg += 0\n",
    "                else:\n",
    "                    avg += 0\n",
    "                final_labels.append(self.labels[selection[1]])\n",
    "            \n",
    "            myset = set()\n",
    "            # check to see how many different tags there are\n",
    "            if not self.isClassification:\n",
    "                divideBy = 0\n",
    "            for label in final_labels:\n",
    "                if not self.isClassification:\n",
    "                    divideBy += label\n",
    "                myset.add(label)\n",
    "            \n",
    "            if not self.isClassification:\n",
    "                avg /= divideBy\n",
    "            return_values = []\n",
    "            while(len(myset) > 0):\n",
    "                currLabel = myset.pop()\n",
    "                sum = 0\n",
    "                for selection in final_selection:\n",
    "                    # if the labels match\n",
    "                    # mse = self.labels[selection[1]] / \n",
    "                    if self.labels[selection[1]] == currLabel:\n",
    "                        # sum the weighted output\n",
    "                        if selection[0] != 0:\n",
    "                            sum += 1/selection[0]**2\n",
    "                        else:\n",
    "                            sum += 0\n",
    "                return_values.append([sum, currLabel])\n",
    "            return_values = sorted(return_values, key=lambda x: x[0])\n",
    "            # return the one that is the highest\n",
    "            if self.isClassification:\n",
    "                return return_values[len(return_values) - 1][1]\n",
    "            else:\n",
    "                return avg\n",
    "            # FIXME not sure what to do for regression?\n",
    "        \n",
    "        else:\n",
    "            for selection in final_selection:\n",
    "                final_labels.append(self.labels[selection[1]])\n",
    "            # --------------------------- NEED TO FIX THIS SECTION -------------------------\n",
    "            # If regression, return the mean of the K labels\n",
    "            res = max(set(final_labels), key = final_labels.count)\n",
    "            sum = 0\n",
    "            count = 0\n",
    "            for selection in final_selection:\n",
    "                if selection[1] == res:\n",
    "                    count += 1\n",
    "                    sum += selection[0]\n",
    "            \n",
    "            if count != 0:\n",
    "                avg = sum / count\n",
    "            \n",
    "\n",
    "        # If classification, return the mode of the K labels\n",
    "        # res = max(set(final_labels), key = final_labels.count)\n",
    "\n",
    "        # print(res)\n",
    "        if self.isClassification:\n",
    "            return res\n",
    "        else:\n",
    "            return avg\n",
    "\n",
    "    #Returns the Mean score given input data and labels\n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with data, excluding targets\n",
    "            y (array-like): A 2D numpy array with targets\n",
    "        Returns:\n",
    "            score : float\n",
    "                Mean accuracy of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            predictions.append(self.predict(x))\n",
    "\n",
    "        sum = 0\n",
    "        mse = 0\n",
    "        for inc in range(len(predictions)):\n",
    "            mse = (y[inc] - predictions[inc])**2\n",
    "            if predictions[inc] == y[inc]:\n",
    "                sum += 1\n",
    "        mse /= len(predictions)\n",
    "        sum /= len(predictions)\n",
    "        if self.isClassification == True:\n",
    "            return sum\n",
    "        else:\n",
    "            return mse\n",
    "\n",
    "    def setK(self, kToSetTo):\n",
    "        self.K = kToSetTo\n",
    "\n",
    "    def setClassification(self, classifcationToSet):\n",
    "        self.isClassification = classifcationToSet\n",
    "    \n",
    "    def setIsWeighted(self, weightedToSet):\n",
    "        self.isWeighted = weightedToSet\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Debug and Evaluation\n",
    "\n",
    "Debug and Evaluate your model using the parameters below:\n",
    "\n",
    "- Use distance weighting\n",
    "- KNN = 3 (three nearest neighbors)\n",
    "- Don’t normalize the data\n",
    "- Use Euclidean Distance\n",
    "\n",
    "---\n",
    "\n",
    "### 1.1.1 Debug\n",
    "\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/glass_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/glass_test.arff)\n",
    "- Use distance weighting\n",
    "- KNN = 3 (three nearest neighbors)\n",
    "- Don’t normalize the data\n",
    "- Use Euclidean Distance\n",
    "\n",
    "Expected Results:\n",
    "- Not using inverse weighted distancing = roughly [68.29%]\n",
    "- Link to [debug solution](https://github.com/cs472ta/CS472/blob/master/debug_solutions/glass_no_inv_prediction.csv)\n",
    "\n",
    "- Using inverse weighted distancing = roughly [74.39%]\n",
    "- Link to [debug solution](https://github.com/cs472ta/CS472/blob/master/debug_solutions/glass_inv_prediction.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12431  100 12431    0     0  24762      0 --:--:-- --:--:-- --:--:-- 24762\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  5431  100  5431    0     0   8512      0 --:--:-- --:--:-- --:--:--  8499\n",
      "Not using Inverse-Weighting:  0.7073170731707317\n",
      "Using Inverse-Weighting:  0.7682926829268293\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/glass_train.arff --output debug_data.arff\n",
    "debug_data = arff.loadarff('debug_data.arff')\n",
    "debug_df = pd.DataFrame(debug_data[0])\n",
    "\n",
    "debug_df['Type'] = debug_df['Type'].str.decode('utf-8')\n",
    "# debug_df.head()\n",
    "\n",
    "debug_np = debug_df.to_numpy()\n",
    "debug_training_np = debug_np.tolist()\n",
    "\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/glass_test.arff --output debug_data.arff\n",
    "debug_data = arff.loadarff('debug_data.arff')\n",
    "debug_df = pd.DataFrame(debug_data[0])\n",
    "\n",
    "debug_df['Type'] = debug_df['Type'].str.decode('utf-8')\n",
    "# debug_df.head()\n",
    "debug_np = debug_df.to_numpy()\n",
    "debug_test_np = debug_np.tolist()\n",
    "\n",
    "# print(len(debug_training_np))\n",
    "# print(len(debug_test_np))\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for x in debug_training_np:\n",
    "    X_train.append(x[0:len(x)-1])\n",
    "    y_train.append(x[len(x)-1])\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for x in debug_test_np:\n",
    "    X_test.append(x[0:len(x)-1])\n",
    "    y_test.append(x[len(x)-1])\n",
    "\n",
    "# Load glass data\n",
    "\n",
    "# Train on training set\n",
    "model = KNNClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "model.setIsWeighted(False)\n",
    "print('Not using Inverse-Weighting: ', model.score(X_test, y_test))\n",
    "model.setIsWeighted(True)\n",
    "print('Using Inverse-Weighting: ', model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Evaluate\n",
    "\n",
    "We will evaluate your model based on its performance on the [diabetes](https://archive.ics.uci.edu/ml/datasets/Diabetes) problem.\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/diabetes_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/diabetes_test.arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 37419  100 37419    0     0   103k      0 --:--:-- --:--:-- --:--:--  102k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 73698  100 73698    0     0   224k      0 --:--:-- --:--:-- --:--:--  224k\n",
      "Not using Inverse-Weighting:  0.8346354166666666\n",
      "Using Inverse-Weighting:  0.8815104166666666\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/diabetes_train.arff --output diabetes_train_data.arff\n",
    "diabetes_train_data = arff.loadarff('diabetes_train_data.arff')\n",
    "diabetes_train_df = pd.DataFrame(diabetes_train_data[0])\n",
    "diabetes_train_df['class'] = diabetes_train_df['class'].str.decode('utf-8')\n",
    "#print(diabetes_train_df.head())\n",
    "\n",
    "diabetes_train_np = diabetes_train_df.to_numpy()\n",
    "diabetes_train_np = diabetes_train_np.tolist()\n",
    "\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/diabetes_test.arff --output diabetes_test_data.arff\n",
    "diabetes_test_data = arff.loadarff('diabetes_test_data.arff')\n",
    "diabetes_test_df = pd.DataFrame(diabetes_test_data[0])\n",
    "diabetes_test_df['class'] = diabetes_test_df['class'].str.decode('utf-8')\n",
    "#print(diabetes_test_df.head())\n",
    "\n",
    "diabetes_test_np = diabetes_test_df.to_numpy()\n",
    "diabetes_test_np = diabetes_test_np.tolist()\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for x in diabetes_train_np:\n",
    "    X_train.append(x[0:len(x)-1])\n",
    "    y_train.append(x[len(x)-1])\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for x in diabetes_test_np:\n",
    "    X_test.append(x[0:len(x)-1])\n",
    "    y_test.append(x[len(x)-1])\n",
    "\n",
    "# Load diabetes data\n",
    "\n",
    "# Train on training set\n",
    "model = KNNClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "model.setIsWeighted(False)\n",
    "print('Not using Inverse-Weighting: ', model.score(X_test, y_test))\n",
    "model.setIsWeighted(True)\n",
    "print('Using Inverse-Weighting: ', model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vWiTdlbR2Xh"
   },
   "source": [
    "## 2. (10%) Use the k-nearest neighbor algorithm (without distance weighting) for the [magic telescope](http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope) problem\n",
    "\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/magic_telescope_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/magic_telescope_test.arff) \n",
    "\n",
    "### 2.1\n",
    "- Try it with k=3 and without normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  937k  100  937k    0     0  1202k      0 --:--:-- --:--:-- --:--:-- 1200k\n",
      "   fLength   fWidth   fSize   fConc  fConc1    fAsym  fM3Long  fM3Trans  \\\n",
      "0  22.7815  14.9526  2.4362  0.4982  0.2509 -14.2836  -9.3635   13.0939   \n",
      "1  40.6756  15.5940  2.7447  0.2772  0.1449  19.6226   9.0297    7.4157   \n",
      "2  12.8427  11.3821  2.1255  0.7191  0.4232 -14.9637   8.5891    6.9418   \n",
      "3  77.0262  32.2880  3.3502  0.3152  0.1868 -28.6712 -35.9464  -31.4001   \n",
      "4  27.5146  11.2114  2.6637  0.4643  0.2687  42.4467  33.0422   -6.3980   \n",
      "\n",
      "    fAlpha     fDist class  \n",
      "0   3.0779  141.5620     g  \n",
      "1  15.4260  193.2340     g  \n",
      "2  82.4198  183.9790     g  \n",
      "3   0.8940  357.0440     g  \n",
      "4  50.3004  239.8878     h  \n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  505k  100  505k    0     0   852k      0 --:--:-- --:--:-- --:--:--  851k\n",
      "   fLength   fWidth   fSize   fConc  fConc1    fAsym  fM3Long  fM3Trans  \\\n",
      "0  30.5540  21.1807  2.7509  0.2715  0.1500   2.1798 -20.8938  -15.2262   \n",
      "1  59.2444  10.4634  2.8051  0.4019  0.1971  49.4360  25.1317    7.0386   \n",
      "2  43.2183  22.3250  3.0828  0.2884  0.1715 -59.4190 -26.8643  -16.6142   \n",
      "3  22.3630  11.6285  2.4793  0.5937  0.3566   9.8142  21.2192    6.6890   \n",
      "4  41.8044  20.9524  2.7348  0.2468  0.1280  72.2250 -22.3472   17.6023   \n",
      "\n",
      "    fAlpha    fDist class  \n",
      "0   2.2982  197.390     g  \n",
      "1  71.0828   48.129     h  \n",
      "2   4.1112  279.854     g  \n",
      "3  38.9391  148.678     h  \n",
      "4  22.3263  122.320     g  \n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/magic_telescope_train.arff --output telescope_train_data.arff\n",
    "telescope_train_data = arff.loadarff('telescope_train_data.arff')\n",
    "telescope_train_df = pd.DataFrame(telescope_train_data[0])\n",
    "telescope_train_df['class'] = telescope_train_df['class'].str.decode('utf-8')\n",
    "for col in telescope_train_df:\n",
    "    if col != 'class':\n",
    "        telescope_train_df[col] = telescope_train_df[col].astype(float)\n",
    "#print(diabetes_train_df.head())\n",
    "\n",
    "telescope_train_np = telescope_train_df.to_numpy()\n",
    "telescope_train_np = telescope_train_np.tolist()\n",
    "print(telescope_train_df.head())\n",
    "\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/magic_telescope_test.arff --output telescope_test_data.arff\n",
    "telescope_test_data = arff.loadarff('telescope_test_data.arff')\n",
    "telescope_test_df = pd.DataFrame(telescope_test_data[0])\n",
    "telescope_test_df['class'] = telescope_test_df['class'].str.decode('utf-8')\n",
    "for col in telescope_test_df:\n",
    "    if col != 'class':\n",
    "        telescope_test_df[col] = telescope_test_df[col].astype(float)\n",
    "\n",
    "telescope_test_np = telescope_test_df.to_numpy()\n",
    "telescope_test_np = telescope_test_np.tolist()\n",
    "print(telescope_test_df.head())\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for x in telescope_train_np:\n",
    "    X_train.append(x[0:len(x)-1])\n",
    "    y_train.append(x[len(x)-1])\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for x in telescope_test_np:\n",
    "    X_test.append(x[0:len(x)-1])\n",
    "    y_test.append(x[len(x)-1])\n",
    "\n",
    "# Load magic telescope data\n",
    "# print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Inverse-Weighting:  0.8093309330933093\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict without normalization\n",
    "model = KNNClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "model.setIsWeighted(False)\n",
    "print('Not using Inverse-Weighting: ', model.score(X_test, y_test))\n",
    "# model.setIsWeighted(True)\n",
    "# print('Using Inverse-Weighting: ', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "- Try it with k=3 and with normalization (input features normalized between 0 and 1). Use the normalization formula (x-xmin)/(xmax-xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [0.35294117647058826, 0.7437185929648241, 0.5901639344262295, 0.35353535353535354, 0.0, 0.5007451564828614, 0.23441502988898377, 0.48333333333333334]\n",
      "X_test:  [0.25656488235294117, 0.7612573467336684, 0.5961878114754099, 0.3549416868686868, 0.0008475378250591016, 0.5451267064083458, 1.8518761742100767, 0.5484687833333334]\n"
     ]
    },
    {
     "data": {
      "text/plain": "KNNClassifier()"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizeData(input):\n",
    "    columns = []\n",
    "    maxValues = []\n",
    "    minValues = []\n",
    "\n",
    "    # for the number of columns\n",
    "    for item in range(len(input[0])):\n",
    "        # for each row\n",
    "        temp = []\n",
    "        for value in range(len(input)):\n",
    "            temp.append(input[value][item])\n",
    "\n",
    "        columns.append(temp)\n",
    "    \n",
    "    for item in columns:\n",
    "        maxValues.append(max(item))\n",
    "        minValues.append(min(item))\n",
    "    # print('col: ', columns)\n",
    "    # print('max: ', maxValues)\n",
    "    # print('min: ', minValues)\n",
    "    return maxValues, minValues\n",
    "\n",
    "print('X_train: ', X_train[0])\n",
    "print('X_test: ', X_test[0])\n",
    "\n",
    "maxValues, minValues = normalizeData(X_train)\n",
    "for incX in range(len(X_train)):\n",
    "    for valX in range(len(X_train[incX])):\n",
    "        X_train[incX][valX] = (X_train[incX][valX] - minValues[valX]) / (maxValues[valX] - minValues[valX])\n",
    "\n",
    "# maxValues, minValues = normalizeData(X_test)\n",
    "for incX in range(len(X_test)):\n",
    "    for valX in range(len(X_test[incX])):\n",
    "        X_test[incX][valX] = (X_test[incX][valX] - minValues[valX]) / (maxValues[valX] - minValues[valX])\n",
    "\n",
    "#print('max: ', maxValues)\n",
    "#print('min: ', minValues)\n",
    "#print('X_train: ', X_train[0])\n",
    "#print('X_test: ', X_test[0])\n",
    "\n",
    "# Train/Predict with normalization\n",
    "model = KNNClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "# model.setIsWeighted(False)\n",
    "# print('Not using Inverse-Weighting: ', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Inverse-Weighting:  0.8372337233723373\n"
     ]
    }
   ],
   "source": [
    "model.setIsWeighted(False)\n",
    "print('Not using Inverse-Weighting: ', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss the accuracy results of using normalized data vs. unnormalized data* --------- The accuracy of the normalized data vs. the unnormalized data was roughly 4% better than the unnormalized data. I could see that normalizing the data would be incredibly beneficial especially when it came to making a more robust system. Especially because test values are not going to be known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "\n",
    "- Using your normalized data, create one graph with classification accuracy on the test set over k values. \n",
    "    - Use odd values of k from 1 to 15.\n",
    "- As a rough sanity check, typical knn accuracies for the magic telescope data set are 75-85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed:  1\n",
      "completed:  3\n",
      "completed:  5\n",
      "completed:  7\n",
      "completed:  9\n",
      "completed:  11\n",
      "completed:  13\n",
      "completed:  15\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict with normalization using k=1,3,...,15\n",
    "scores = []\n",
    "k_values = []\n",
    "for i in range(15):\n",
    "    if i % 2 == 0:\n",
    "        model.setK(i+1)\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "        print('completed: ', i+1)\n",
    "        k_values.append(i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8172817281728173, 0.8372337233723373, 0.8453345334533453, 0.8468346834683468, 0.8471347134713472, 0.8472847284728473, 0.8496849684968497, 0.8474347434743474]\n",
      "[1, 3, 5, 7, 9, 11, 13, 15]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x12f15d970>]"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph classification accuracy over k\n",
    "print(scores)\n",
    "print(k_values)\n",
    "plt.plot(k_values, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the rest of the experiments use only normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIRG42TgSR4x"
   },
   "source": [
    "## 3. (10%) Use the regression variation of your algorithm (without distance weighting) for the [housing price prediction](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) problem.\n",
    "\n",
    "- Use this [training set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_train.arff) and this [test set](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_test.arff).\n",
    "- Use Mean Square Error (MSE) on the test set as your accuracy metric for this case.\n",
    "    - Do not normalize regression output values\n",
    "- Graph MSE on the test set with odd values of k from 1 to 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "KBGUn43ASiXW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 34205  100 34205    0     0   115k      0 --:--:-- --:--:-- --:--:--  115k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3885  100  3885    0     0  13036      0 --:--:-- --:--:-- --:--:-- 13036\n"
     ]
    },
    {
     "data": {
      "text/plain": "KNNClassifier()"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load housing price prediction data\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_train.arff --output housing_train_data.arff\n",
    "housing_train_data = arff.loadarff('housing_train_data.arff')\n",
    "housing_train_df = pd.DataFrame(housing_train_data[0])\n",
    "housing_train_df = housing_train_df.astype(float)\n",
    "# print(housing_train_df.head())\n",
    "housing_train_np = housing_train_df.to_numpy()\n",
    "housing_train_np = housing_train_np.tolist()\n",
    "#print(housing_train_np)\n",
    "\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/housing_test.arff --output housing_test_data.arff\n",
    "housing_test_data = arff.loadarff('housing_test_data.arff')\n",
    "housing_test_df = pd.DataFrame(housing_test_data[0])\n",
    "housing_test_df = housing_test_df.astype(float)\n",
    "\n",
    "housing_test_np = housing_test_df.to_numpy()\n",
    "housing_test_np = housing_test_np.tolist()\n",
    "\n",
    "\n",
    "X_train_housing = []\n",
    "y_train_housing = []\n",
    "for x in housing_train_np:\n",
    "    X_train_housing.append(x[0:len(x)-1])\n",
    "    y_train_housing.append(x[len(x)-1])\n",
    "\n",
    "X_test_housing = []\n",
    "y_test_housing = []\n",
    "for x in housing_test_np:\n",
    "    X_test_housing.append(x[0:len(x)-1])\n",
    "    y_test_housing.append(x[len(x)-1])\n",
    "\n",
    "\n",
    "\n",
    "maxValues, minValues = normalizeData(X_train_housing)\n",
    "for incX in range(len(X_train_housing)):\n",
    "    for valX in range(len(X_train_housing[incX])):\n",
    "        X_train_housing[incX][valX] = (X_train_housing[incX][valX] - minValues[valX]) / (maxValues[valX] - minValues[valX])\n",
    "\n",
    "# maxValues, minValues = normalizeData(X_test)\n",
    "for incX in range(len(X_test_housing)):\n",
    "    for valX in range(len(X_test_housing[incX])):\n",
    "        X_test_housing[incX][valX] = (X_test_housing[incX][valX] - minValues[valX]) / (maxValues[valX] - minValues[valX])\n",
    "\n",
    "model2 = KNNClassifier()\n",
    "model2.setClassification(False)\n",
    "model2.setIsWeighted(False)\n",
    "model2.fit(X_train_housing, y_train_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed:  1\n",
      "completed:  3\n",
      "completed:  5\n",
      "completed:  7\n",
      "completed:  9\n",
      "completed:  11\n",
      "completed:  13\n",
      "completed:  15\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict using k=1,3,...,15\n",
    "scores2 = []\n",
    "k_values2 = []\n",
    "for i in range(15):\n",
    "    if i % 2 == 0:\n",
    "            model2.setK(i+1)\n",
    "            scores2.append(model2.score(X_test_housing, y_test_housing))\n",
    "            print('completed: ', i+1)\n",
    "            k_values2.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.534117647058824, 5.534117647058824, 5.534117647058824, 5.534117647058824, 5.534117647058824, 5.534117647058824, 5.534117647058824, 5.534117647058824]\n",
      "[1, 3, 5, 7, 9, 11, 13, 15]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x12cbd7b80>]"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph MSE over k\n",
    "# Graph classification accuracy over k\n",
    "print(scores2)\n",
    "print(k_values2)\n",
    "plt.plot(k_values2, scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v19fpixqTe-7"
   },
   "source": [
    "## 4. (15%) Repeat your experiments for magic telescope and housing using distance-weighted (inverse of distance squared) voting and discuss your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Magic Telescope Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "ZCPFUAGTS2sX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "KNNClassifier()"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Predict magic telescope using distance-weighted voting\n",
    "model3 = KNNClassifier()\n",
    "model3.setClassification(True)\n",
    "model3.setIsWeighted(True)\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-105-3bfbdb30aad3>:101: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  sum += 1/selection[0]**2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-5c5919328079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mscores3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'completed: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mk_values3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-3bfbdb30aad3>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-3bfbdb30aad3>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# print('data: ', data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;31m# print('item: ', item)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0msum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;31m# Add the distance and the index of the example to an ordered collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdistances_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores3 = []\n",
    "k_values3 = []\n",
    "for i in range(15):\n",
    "    if i == 3 or i == 7:\n",
    "            model3.setK(i+1)\n",
    "            scores3.append(model3.score(X_test, y_test))\n",
    "            print('completed: ', i+1)\n",
    "            k_values3.append(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "KNNClassifier()"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Predict housing using distance-weighted voting\n",
    "model4 = KNNClassifier()\n",
    "model4.setClassification(False)\n",
    "model4.setIsWeighted(True)\n",
    "model4.fit(X_train_housing, y_train_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed:  1\n",
      "completed:  3\n",
      "completed:  5\n",
      "completed:  7\n",
      "completed:  9\n",
      "completed:  11\n",
      "completed:  13\n",
      "completed:  15\n"
     ]
    }
   ],
   "source": [
    "scores4 = []\n",
    "k_values4 = []\n",
    "for i in range(15):\n",
    "    if i % 2 == 0:\n",
    "            model4.setK(i+1)\n",
    "            scores4.append(model4.score(X_test_housing, y_test_housing))\n",
    "            print('completed: ', i+1)\n",
    "            k_values4.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.660394501635618, 2.5939840393810325, 0.09083397722480108, 0.09398081439653426, 0.4169789254955246, 0.7504350347865282, 1.0415002391439967, 1.3080479671085947]\n",
      "[1, 3, 5, 7, 9, 11, 13, 15]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x12f1c56d0>]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph classification accuracy over k\n",
    "print(scores4)\n",
    "print(k_values4)\n",
    "plt.plot(k_values4, scores4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss your results* ------ Something that I noticed is that the model had an issue learning the regression case when weights were not involved. However, once the weights were included, the model began to learn much better. It even began to overfit I dare say."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (10%) Use the k-nearest neighbor algorithm to solve the [credit-approval](https://archive.ics.uci.edu/ml/datasets/Credit+Approval) (credit-a) problem.\n",
    "\n",
    "- Use this [dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/credit_approval.arff)\n",
    "    - Use a 70/30 split of the data for the training/test set\n",
    "- Note that this set has both continuous and nominal attributes, together with don’t know values. \n",
    "- Implement and justify a distance metric which supports continuous, nominal, and don’t know attribute values\n",
    "    - You need to handle don't knows with the distance metric, not by imputing a value.\n",
    "    - More information on distance metrics can be found [here](https://www.jair.org/index.php/jair/article/view/10182/24168).\n",
    "- Use your own choice for k.\n",
    "- As a rough sanity check, typical knn accuracies for the credit data set are 70-80%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/credit_approval.arff --output credit_data.arff\n",
    "credit_data = arff.loadarff('credit_data.arff')\n",
    "credit_df = pd.DataFrame(credit_data[0])\n",
    "A1_mask = {'a':0, '?':-1, 'b':1}\n",
    "A4_mask = {'l':0, '?':-1, 'u':1, 'y':2}\n",
    "A5_mask = {'g':0, 'gg':1, '?':-1, 'p':2}\n",
    "A6_mask = {'j':0, 'aa':1, 'w':2, 'd':3, 'c':4, 'q':5, 'i':6, 'cc':7, 'ff':8, 'r':9, 'x':10, 'k':11, 'e':12, 'm':13, '?':-1}\n",
    "A7_mask = {'j':0, 'ff':1, 'bb':2, 'z':3, 'v':4, 'dd':5, 'o':6, 'h':7, 'n':8, '?':-1}\n",
    "A9_10_12_mask = {'f':0, 't':1}\n",
    "A13_mask = {'s':0, 'g':1, 'p':2}\n",
    "class_mask = {'-':0, '+':1}\n",
    "\n",
    "credit_df['A1'] = credit_df['A1'].str.decode('utf-8')\n",
    "credit_df['A1'] = credit_df['A1'].map(A1_mask)\n",
    "credit_df['A4'] = credit_df['A4'].str.decode('utf-8')\n",
    "credit_df['A4'] = credit_df['A4'].map(A4_mask)\n",
    "credit_df['A5'] = credit_df['A5'].str.decode('utf-8')\n",
    "credit_df['A5'] = credit_df['A5'].map(A5_mask)\n",
    "credit_df['A6'] = credit_df['A6'].str.decode('utf-8')\n",
    "credit_df['A6'] = credit_df['A6'].map(A6_mask)\n",
    "credit_df['A7'] = credit_df['A7'].str.decode('utf-8')\n",
    "credit_df['A7'] = credit_df['A7'].map(A7_mask)\n",
    "credit_df['A9'] = credit_df['A9'].str.decode('utf-8')\n",
    "credit_df['A9'] = credit_df['A9'].map(A9_10_12_mask)\n",
    "credit_df['A10'] = credit_df['A10'].str.decode('utf-8')\n",
    "credit_df['A10'] = credit_df['A10'].map(A9_10_12_mask)\n",
    "credit_df['A12'] = credit_df['A12'].str.decode('utf-8')\n",
    "credit_df['A12'] = credit_df['A12'].map(A9_10_12_mask)\n",
    "credit_df['A13'] = credit_df['A13'].str.decode('utf-8')\n",
    "credit_df['A13'] = credit_df['A13'].map(A13_mask)\n",
    "credit_df['class'] = credit_df['class'].str.decode('utf-8')\n",
    "credit_df['class'] = credit_df['class'].map(class_mask)\n",
    "\n",
    "credit_np = credit_df.to_numpy()\n",
    "credit_np = credit_np.tolist()\n",
    "#print(credit_np)\n",
    "\n",
    "count = 0.3 * len(credit_np)\n",
    "count = int(count)\n",
    "print('cnt: ', count)\n",
    "\n",
    "test_set = []\n",
    "while(len(test_set) < count):\n",
    "    pos = random.randint(0, len(test_set))\n",
    "    test_set.append(credit_np[pos])\n",
    "    del credit_np[pos]\n",
    "\n",
    "print()\n",
    "\n",
    "\"\"\"A1_list = set()\n",
    "A4_list = set()\n",
    "A5_list = set()\n",
    "A6_list = set()\n",
    "A7_list = set()\n",
    "A9_list = set()\n",
    "A10_list = set()\n",
    "A12_list = set()\n",
    "A13_list = set()\n",
    "class_list = set()\n",
    "\n",
    "for item in credit_df['A1']:\n",
    "    A1_list.add(item)\n",
    "for item in credit_df['A4']:\n",
    "    A4_list.add(item)\n",
    "for item in credit_df['A5']:\n",
    "    A5_list.add(item)\n",
    "for item in credit_df['A6']:\n",
    "    A6_list.add(item)\n",
    "for item in credit_df['A7']:\n",
    "    A7_list.add(item)\n",
    "for item in credit_df['A9']:\n",
    "    A9_list.add(item)\n",
    "for item in credit_df['A10']:\n",
    "    A10_list.add(item)\n",
    "for item in credit_df['A12']:\n",
    "    A12_list.add(item)\n",
    "for item in credit_df['A13']:\n",
    "    A13_list.add(item)\n",
    "for item in credit_df['class']:\n",
    "    class_list.add(item)\n",
    "\n",
    "print('A1: ', A1_list)\n",
    "print('A4: ', A4_list)\n",
    "print('A5: ', A5_list)\n",
    "print('A6: ', A6_list)\n",
    "print('A7: ', A7_list)\n",
    "print('A9: ', A9_list)\n",
    "print('A10: ', A10_list)\n",
    "print('A12: ', A12_list)\n",
    "print('A13: ', A13_list)\n",
    "print('class: ', class_list)\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load dataset and split into train/test sets\n",
    "\n",
    "# Train/Predict credit-approval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain and justify your distance metric*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBBmeNQ7jvcQ"
   },
   "source": [
    "## 6. (15%) Use the scikit's KNN Classifier on magic telescope and KNN Regressor on housing and compare your results.\n",
    "\n",
    "- Try out different hyperparameters to see how well you can do. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "OFQv70W2VyqJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telescope:  0.8658854166666666\n",
      "Housing:  0.7991753902998118\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict magic telescope using scikit's KNN\n",
    "classifier = KNeighborsClassifier(3, weights='distance')\n",
    "classifier.fit(X_train, y_train)\n",
    "print('Telescope: ', classifier.score(X_test, y_test))\n",
    "\n",
    "# Train/Predict housing using scikit's KNN\n",
    "regressor = KNeighborsRegressor(3, weights='distance')\n",
    "regressor.fit(X_train_housing, y_train_housing)\n",
    "print('Housing: ', regressor.score(X_test_housing, y_test_housing))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqSFAXwlk3Ms"
   },
   "source": [
    "*Report your comparison* --------- Surprisingly enough, my model was fairly comparable to the sklearn models this time around. Other than beingg much slower, I got similar values and accuracies when it came to the different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTlK-kijk8Mg"
   },
   "source": [
    "## 7. (optional 5% extra credit): For the best value of k for any one of the datasets, implement a reduction algorithm that removes data points in some rational way such that performance does not drop too drastically on the test set given the reduced training set.\n",
    "\n",
    "- Compare your performance on the test set for the reduced and non-reduced versions and give the number (and percentage) of training examples removed from the original training set. How well does your reduction algorithm work?\n",
    "    - Note that performance for magic telescope is classification accuracy and for housing it is mean squared error.\n",
    "    - Magic Telescope has about 12,000 instances and if you use a leave one out style of testing for your data set reduction, then your algorithm will run slow since that is n2 at each step.\n",
    "    - If you wish, you may use a random subset of 2,000 of the magic telescope instances.\n",
    "    - More information on reduction techniques can be found [here](http://axon.cs.byu.edu/~martinez/classes/478/slides/IBL.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iY77P7gk1Nh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab 1 - perceptron",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python382jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}